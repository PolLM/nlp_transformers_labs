{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries, Keys and Values\n",
    "\n",
    "I will ommit the batch dimension, I will assume that the input embeddings are of shape (seq_length, d_e) and the output embeddings are of shape (seq_length, d_emb).\n",
    "\n",
    "I will do some math to understand it better (also looking at https://arxiv.org/abs/1706.03762):\n",
    "\n",
    "Notation:\n",
    "\n",
    "* Values matrix: $V \\in \\mathbb{R}^{seq\\_length \\times d_{e}}$\n",
    "* Single value vector: $v_i \\in \\mathbb{R}^{d_{e}}$\n",
    "* Keys matrix: $K \\in \\mathbb{R}^{seq\\_length \\times d_{k}}$+\n",
    "* Single key vector: $k_i \\in \\mathbb{R}^{d_{k}}$\n",
    "* Queries matrix: $Q \\in \\mathbb{R}^{seq\\_length \\times d_{q}}$\n",
    "* Single query vector: $q_i \\in \\mathbb{R}^{d_{q}}$\n",
    "\n",
    "\n",
    "$$V = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_{seq\\_length} \\end{bmatrix} K = \\begin{bmatrix} k_1 \\\\ k_2 \\\\ \\vdots \\\\ k_{seq\\_length} \\end{bmatrix} Q = \\begin{bmatrix} q_1 \\\\ q_2 \\\\ \\vdots \\\\ q_{seq\\_length} \\end{bmatrix}$$\n",
    "\n",
    "1. **Dot product between queries and keys**:\n",
    "\n",
    "$$ \\frac{Q \\cdot K^T}{\\sqrt{d_{k}}} = \\frac{1}{\\sqrt{d_{k}}} \\begin{bmatrix} q_1 \\cdot k_1 & q_1 \\cdot k_2 & \\cdots & q_1 \\cdot k_{seq\\_length} \\\\ q_2 \\cdot k_1 & q_2 \\cdot k_2 & \\cdots & q_2 \\cdot k_{seq\\_length} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ q_{seq\\_length} \\cdot k_1 & q_{seq\\_length} \\cdot k_2 & \\cdots & q_{seq\\_length} \\cdot k_{seq\\_length} \\end{bmatrix}$$\n",
    "\n",
    "2. **Softmax**:\n",
    "\n",
    "$$ W = \\text{softmax} \\left( \\frac{Q \\cdot K^T}{\\sqrt{d_{k}}} \\right) = \\begin{bmatrix} w_{1,1} & w_{1,2} & \\cdots & w_{1,seq\\_length} \\\\ w_{2,1} & w_{2,2} & \\cdots & w_{2,seq\\_length} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ w_{seq\\_length,1} & w_{seq\\_length,2} & \\cdots & w_{seq\\_length,seq\\_length} \\end{bmatrix} $$\n",
    "\n",
    "$$where \\sum_{j = 1}^{seq\\_length} w_{ij} = 1 \\quad \\forall i  $$\n",
    "\n",
    "3. **Weighted sum of values**:\n",
    "\n",
    "$$ X^{'} =  \\begin{bmatrix} x^{'}_1 \\\\ x^{'}_2 \\\\ \\vdots \\\\ x^{'}_{seq\\_length} \\end{bmatrix} = W \\cdot V = \\begin{bmatrix} w_{1,1} & w_{1,2} & \\cdots & w_{1,seq\\_length} \\\\ w_{2,1} & w_{2,2} & \\cdots & w_{2,seq\\_length} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ w_{seq\\_length,1} & w_{seq\\_length,2} & \\cdots & w_{seq\\_length,seq\\_length} \\end{bmatrix} \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_{seq\\_length} \\end{bmatrix} $$\n",
    "\n",
    "$$so, \\quad x^{'}_i = \\sum_{j = 1}^{seq\\_length} w_{ij} \\cdot v_j $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "tensor([[ 2051, 10029,  2066,  2019,  8612]])\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "sentence = \"time flies like an arrow\"\n",
    "\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False)\n",
    "print(inputs.input_ids.shape)\n",
    "print(inputs.input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the config parameters fromt he model\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "#learnable embeddings that acts as a lookup table\n",
    "token_emb = torch.nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "token_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 768])\n",
      "tensor([[[ 6.6525e-01, -3.2743e-01,  4.4065e-01,  ..., -7.4415e-03,\n",
      "          -1.8935e-02, -5.1604e-01],\n",
      "         [-2.8991e-01,  1.1964e+00, -1.2789e+00,  ..., -1.2697e-01,\n",
      "          -4.4247e-01, -1.3083e+00],\n",
      "         [-3.2184e-01, -1.1409e+00,  1.2393e+00,  ..., -1.5396e-03,\n",
      "          -2.1357e-03,  7.1527e-01],\n",
      "         [-8.4413e-01, -9.1694e-01,  1.1774e+00,  ..., -5.1015e-01,\n",
      "          -9.6122e-01,  5.2684e-01],\n",
      "         [ 1.2174e+00,  1.9181e+00,  1.5767e-01,  ..., -2.4287e+00,\n",
      "           2.8732e-01, -1.0570e+00]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs_embeds = token_emb(inputs.input_ids)\n",
    "print(inputs_embeds.size())\n",
    "print(inputs_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of scores: torch.Size([1, 5, 5])\n",
      "\n",
      "Size of weights: torch.Size([1, 5, 5])\n",
      "Check if the sum of weights is 1: tensor([[1., 1., 1., 1., 1.]], grad_fn=<SumBackward1>)\n",
      "\n",
      "Size of att_outputs: torch.Size([1, 5, 768])\n",
      "att_outputs: tensor([[[ 6.6525e-01, -3.2743e-01,  4.4065e-01,  ..., -7.4415e-03,\n",
      "          -1.8935e-02, -5.1604e-01],\n",
      "         [-2.8991e-01,  1.1964e+00, -1.2789e+00,  ..., -1.2697e-01,\n",
      "          -4.4247e-01, -1.3083e+00],\n",
      "         [-3.2184e-01, -1.1409e+00,  1.2393e+00,  ..., -1.5396e-03,\n",
      "          -2.1357e-03,  7.1527e-01],\n",
      "         [-8.4413e-01, -9.1694e-01,  1.1774e+00,  ..., -5.1015e-01,\n",
      "          -9.6122e-01,  5.2684e-01],\n",
      "         [ 1.2174e+00,  1.9181e+00,  1.5767e-01,  ..., -2.4287e+00,\n",
      "           2.8732e-01, -1.0570e+00]]], grad_fn=<BmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#for simplicity we will compute a single attention head and assume Q = K = V = inputs_embeds\n",
    "# and will ommit the positional embeddings\n",
    "query = key = value = inputs_embeds\n",
    "dim_k = key.size(-1)\n",
    "scores = torch.bmm(query, key.transpose(1, 2)) / math.sqrt(dim_k)\n",
    "print(f\"Size of scores: {scores.size()}\\n\")\n",
    "weights = F.softmax(scores, dim=-1)\n",
    "print(f\"Size of weights: {weights.size()}\")\n",
    "print(f\"Check if the sum of weights is 1: {weights.sum(dim=-1)}\\n\")\n",
    "att_outputs = torch.bmm(weights, value)\n",
    "print(f\"Size of att_outputs: {att_outputs.size()}\")\n",
    "print(f\"att_outputs: {att_outputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-hf-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
