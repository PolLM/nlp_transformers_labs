{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries, Keys and Values\n",
    "\n",
    "I will ommit the batch dimension, I will assume that the input embeddings are of shape (seq_length, d_e) and the output embeddings are of shape (seq_length, d_emb).\n",
    "\n",
    "I will do some math to understand it better (also looking at https://arxiv.org/abs/1706.03762):\n",
    "\n",
    "Notation:\n",
    "\n",
    "* Values matrix: $V \\in \\mathbb{R}^{seq\\_length \\times d_{e}}$\n",
    "* Single value vector: $v_i \\in \\mathbb{R}^{d_{e}}$\n",
    "* Keys matrix: $K \\in \\mathbb{R}^{seq\\_length \\times d_{k}}$+\n",
    "* Single key vector: $k_i \\in \\mathbb{R}^{d_{k}}$\n",
    "* Queries matrix: $Q \\in \\mathbb{R}^{seq\\_length \\times d_{q}}$\n",
    "* Single query vector: $q_i \\in \\mathbb{R}^{d_{q}}$\n",
    "\n",
    "\n",
    "$$V = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_{seq\\_length} \\end{bmatrix} K = \\begin{bmatrix} k_1 \\\\ k_2 \\\\ \\vdots \\\\ k_{seq\\_length} \\end{bmatrix} Q = \\begin{bmatrix} q_1 \\\\ q_2 \\\\ \\vdots \\\\ q_{seq\\_length} \\end{bmatrix}$$\n",
    "\n",
    "1. **Dot product between queries and keys**:\n",
    "\n",
    "$$ \\frac{Q \\cdot K^T}{\\sqrt{d_{k}}} = \\frac{1}{\\sqrt{d_{k}}} \\begin{bmatrix} q_1 \\cdot k_1 & q_1 \\cdot k_2 & \\cdots & q_1 \\cdot k_{seq\\_length} \\\\ q_2 \\cdot k_1 & q_2 \\cdot k_2 & \\cdots & q_2 \\cdot k_{seq\\_length} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ q_{seq\\_length} \\cdot k_1 & q_{seq\\_length} \\cdot k_2 & \\cdots & q_{seq\\_length} \\cdot k_{seq\\_length} \\end{bmatrix}$$\n",
    "\n",
    "2. **Softmax**:\n",
    "\n",
    "$$ W = \\text{softmax} \\left( \\frac{Q \\cdot K^T}{\\sqrt{d_{k}}} \\right) = \\begin{bmatrix} w_{1,1} & w_{1,2} & \\cdots & w_{1,seq\\_length} \\\\ w_{2,1} & w_{2,2} & \\cdots & w_{2,seq\\_length} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ w_{seq\\_length,1} & w_{seq\\_length,2} & \\cdots & w_{seq\\_length,seq\\_length} \\end{bmatrix} $$\n",
    "\n",
    "$$where \\sum_{j = 1}^{seq\\_length} w_{ij} = 1 \\quad \\forall i  $$\n",
    "\n",
    "3. **Weighted sum of values**:\n",
    "\n",
    "$$ X^{'} =  \\begin{bmatrix} x^{'}_1 \\\\ x^{'}_2 \\\\ \\vdots \\\\ x^{'}_{seq\\_length} \\end{bmatrix} = W \\cdot V = \\begin{bmatrix} w_{1,1} & w_{1,2} & \\cdots & w_{1,seq\\_length} \\\\ w_{2,1} & w_{2,2} & \\cdots & w_{2,seq\\_length} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ w_{seq\\_length,1} & w_{seq\\_length,2} & \\cdots & w_{seq\\_length,seq\\_length} \\end{bmatrix} \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_{seq\\_length} \\end{bmatrix} $$\n",
    "\n",
    "$$so, \\quad x^{'}_i = \\sum_{j = 1}^{seq\\_length} w_{ij} \\cdot v_j $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2051, 10029,  2066,  2019,  8612]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ckpt = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "sentence = \"time flies like an arrow\"\n",
    "\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False)\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the config parameters fromt he model\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "#learnable embeddings that acts as a lookup table\n",
    "token_emb = torch.nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "token_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 768])\n",
      "tensor([[[ 0.8201,  0.6045, -0.0150,  ..., -0.5656,  0.3174,  0.8564],\n",
      "         [-0.0386, -1.0203, -0.0138,  ...,  0.4973,  0.9126, -0.1514],\n",
      "         [ 1.1335,  2.5236,  0.5811,  ..., -0.2125,  2.2726,  0.8796],\n",
      "         [ 1.0999,  0.9886,  0.5276,  ...,  0.0387,  0.1758, -1.4119],\n",
      "         [-0.2951,  1.1370, -0.4077,  ..., -0.6754,  0.4314, -0.9594]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs_embeds = token_emb(inputs.input_ids)\n",
    "print(inputs_embeds.size())\n",
    "print(inputs_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of scores: torch.Size([1, 5, 5])\n",
      "\n",
      "Size of weights: torch.Size([1, 5, 5])\n",
      "Check if the sum of weights is 1: tensor([[1., 1., 1., 1., 1.]], grad_fn=<SumBackward1>)\n",
      "\n",
      "Size of att_outputs: torch.Size([1, 5, 768])\n",
      "att_outputs: tensor([[[ 0.8201,  0.6045, -0.0150,  ..., -0.5656,  0.3174,  0.8564],\n",
      "         [-0.0386, -1.0203, -0.0138,  ...,  0.4973,  0.9126, -0.1514],\n",
      "         [ 1.1335,  2.5236,  0.5811,  ..., -0.2125,  2.2726,  0.8796],\n",
      "         [ 1.0999,  0.9886,  0.5276,  ...,  0.0387,  0.1758, -1.4119],\n",
      "         [-0.2951,  1.1370, -0.4077,  ..., -0.6754,  0.4314, -0.9594]]],\n",
      "       grad_fn=<BmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#for simplicity we will compute a single attention head and assume Q = K = V = inputs_embeds\n",
    "query = key = value = inputs_embeds\n",
    "dim_k = key.size(-1)\n",
    "scores = torch.bmm(query, key.transpose(1, 2)) / math.sqrt(dim_k)\n",
    "print(f\"Size of scores: {scores.size()}\\n\")\n",
    "weights = F.softmax(scores, dim=-1)\n",
    "print(f\"Size of weights: {weights.size()}\")\n",
    "print(f\"Check if the sum of weights is 1: {weights.sum(dim=-1)}\\n\")\n",
    "att_outputs = torch.bmm(weights, value)\n",
    "print(f\"Size of att_outputs: {att_outputs.size()}\")\n",
    "print(f\"att_outputs: {att_outputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-hf-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
